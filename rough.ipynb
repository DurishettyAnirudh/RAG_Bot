# spam_filter.py

import pandas as pd
import string
import nltk
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer
from nltk.corpus import stopwords

# Download stopwords if not already downloaded
nltk.download('stopwords')

# Load your dataset
# Make sure your dataset has two columns: 'message' and 'label'
# Example: df = pd.read_csv("spam.csv")
df = pd.read_csv("spam.csv")   # <-- change filename if needed

# Preprocessing function
stop_words = set(stopwords.words('english'))

def preprocess(text):
    # Lowercase + remove punctuation
    text = ''.join(c for c in text.lower() if c not in string.punctuation)
    # Remove stopwords
    return ' '.join(w for w in text.split() if w not in stop_words)

# Apply preprocessing to dataset
df['message'] = df['message'].apply(preprocess)

# Vectorization
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df['message'])
y = df['label']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Train model
model = MultinomialNB()
model.fit(X_train, y_train)

# Accuracy
print("Accuracy:", model.score(X_test, y_test))

# Prediction function
def predict(msg):
    msg = preprocess(msg)
    vec = vectorizer.transform([msg])
    return model.predict(vec)[0]

# Test interactively
print("\nSpam Filter Ready!")
while True:
    user_input = input("Enter message (or 'quit' to stop): ")
    if user_input.lower() == "quit":
        break
    print("Prediction:", predict(user_input))
